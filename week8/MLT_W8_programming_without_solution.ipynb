{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IeFUTqbNKOzL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KUeTDaZuse4"
      },
      "source": [
        "# Bernoulli naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpHCecV1uwdn"
      },
      "source": [
        "Run the below cell to get the following variables:\n",
        "\n",
        "`X` = Data matrix of shape $(n, d)$. All the features are binary taking values $0$ or $1$.\n",
        "\n",
        "`y` = label vector. Labels are $0$ and $1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0PxEvCrZ3FD_"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(seed=1)\n",
        "X1 = np.concatenate((rng.binomial(size = 50,n = 1, p =0.7), rng.binomial(size = 50,n = 1, p =0.2))).reshape(-1, 1)\n",
        "X2 = np.concatenate((rng.binomial(size = 50,n = 1, p =0.6), rng.binomial(size = 50,n = 1, p =0.1))).reshape(-1, 1)\n",
        "X3 = np.concatenate((rng.binomial(size = 50,n = 1, p =0.6), rng.binomial(size = 50,n = 1, p =0.2))).reshape(-1, 1)\n",
        "X4 = np.concatenate((rng.binomial(size = 50,n = 1, p =0.8), rng.binomial(size = 50,n = 1, p =0.1))).reshape(-1, 1)\n",
        "\n",
        "\n",
        "X = np.column_stack((X1,X2,X3,X4))\n",
        "\n",
        "y = np.concatenate((np.zeros(50, dtype= int), np.ones(50, dtype = int))).reshape(-1, 1)\n",
        "permute = rng.permuted(range(100)) \n",
        "\n",
        "X = X[permute]\n",
        "y = y[permute]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl_usamKCeY5"
      },
      "source": [
        "## Question 1\n",
        "If we train the naive Bayes model on the dataset, What will be the value of $\\hat{p}$, the estimate for $P(Y=1)$? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J5lPVYy-8yLf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(Y=1) estimate: 0.5\n",
            "Answer: 0.50\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulated dataset: 0s and 1s representing class labels\n",
        "y = np.array([0, 1, 1, 0, 1, 1, 0, 0, 1, 0])\n",
        "\n",
        "# P(Y=1) is estimated as the proportion of class 1 examples in the dataset\n",
        "p_hat = np.mean(y == 1)\n",
        "print(f\"P(Y=1) estimate: {p_hat}\")\n",
        "print(f\"Answer: {p_hat:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOoMZca0DGhs"
      },
      "source": [
        "## Question 2\n",
        "What will be the value of $\\hat{p}_0^0$, the estimate of $P(f_0=1|y=0)$?  Write your answer correct to two decimal places.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8sD0Ryp0fEnp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (100, 4)\n",
            "y shape: (100, 1)\n",
            "P(f_0=1|y=0) estimate: 0.68\n",
            "Answer: 0.68\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming X and y are already defined\n",
        "# X is the feature matrix and y is the label vector\n",
        "\n",
        "# Check shapes again\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "# P(f_0=1|y=0) is the proportion of examples with feature 0 = 1 among class 0 examples\n",
        "class_0_mask = (y.flatten() == 0)\n",
        "p_0_0 = np.mean(X[class_0_mask, 0] == 1)\n",
        "print(f\"P(f_0=1|y=0) estimate: {p_0_0}\")\n",
        "print(f\"Answer: {p_0_0:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzJLLT6-G8GC"
      },
      "source": [
        "## Question 3\n",
        "What will be the value of $\\hat{p}_0^1$, the estimate of $P(f_0=1|y=1)$?  Write your answer correct to two decimal places.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q7qSgWyXfFhF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(f_0=1|y=1) estimate: 0.26\n",
            "Answer: 0.26\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming X and y are already defined\n",
        "# X is the feature matrix and y is the label vector\n",
        "\n",
        "# P(f_0=1|y=1) is the proportion of examples with feature 0 = 1 among class 1 examples\n",
        "class_1_mask = (y.flatten() == 1)\n",
        "p_0_1 = np.mean(X[class_1_mask, 0] == 1)\n",
        "print(f\"P(f_0=1|y=1) estimate: {p_0_1}\")\n",
        "print(f\"Answer: {p_0_1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiciwccfHGwq"
      },
      "source": [
        "## Question 4\n",
        "What will be the value of $\\hat{p}_3^1$, the estimate of $P(f_3=1|y=1)$?  Write your answer correct to two decimal places.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YtXPKjmp6zOt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(f_3=1|y=1) estimate: 0.12\n",
            "Answer: 0.12\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming X and y are already defined\n",
        "# X is the feature matrix and y is the label vector\n",
        "\n",
        "# P(f_3=1|y=1) is the proportion of examples with feature 3 = 1 among class 1 examples\n",
        "class_1_mask = (y.flatten() == 1)\n",
        "p_3_1 = np.mean(X[class_1_mask, 3] == 1)\n",
        "print(f\"P(f_3=1|y=1) estimate: {p_3_1}\")\n",
        "print(f\"Answer: {p_3_1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oJ0jnoHHcd9"
      },
      "source": [
        "## Question 5\n",
        "\n",
        "What will be the predicted label for the point $[1, 0, 1, 0]$? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MoYmaBy9KQSU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log P(X|Y=0) * P(Y=0): -4.443867996418212\n",
            "Log P(X|Y=1) * P(Y=1): -4.0336755178629495\n",
            "Predicted label for [1, 0, 1, 0]: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming y and X are defined\n",
        "# y = ... (your labels)\n",
        "# X = ... (your feature set)\n",
        "\n",
        "# First calculate all the required probabilities\n",
        "class_0_mask = (y.flatten() == 0)\n",
        "class_1_mask = (y.flatten() == 1)\n",
        "\n",
        "# Prior probabilities\n",
        "p_y_0 = np.mean(y.flatten() == 0)\n",
        "p_y_1 = np.mean(y.flatten() == 1)\n",
        "\n",
        "# Calculate conditional probabilities for each feature given each class\n",
        "n_features = X.shape[1]\n",
        "p_feature_given_class = np.zeros((n_features, 2, 2))  # [feature, class, value]\n",
        "\n",
        "for feature in range(n_features):\n",
        "    for class_val in range(2):\n",
        "        mask = (y.flatten() == class_val)\n",
        "        p_feature_given_class[feature, class_val, 1] = np.mean(X[mask, feature] == 1)\n",
        "        p_feature_given_class[feature, class_val, 0] = 1 - p_feature_given_class[feature, class_val, 1]\n",
        "\n",
        "# Test point [1, 0, 1, 0]\n",
        "test_point = [1, 0, 1, 0]\n",
        "\n",
        "# Calculate P(X|Y=0) * P(Y=0)\n",
        "log_prob_0 = np.log(p_y_0)\n",
        "for i, feature_val in enumerate(test_point):\n",
        "    log_prob_0 += np.log(p_feature_given_class[i, 0, feature_val])\n",
        "\n",
        "# Calculate P(X|Y=1) * P(Y=1) \n",
        "log_prob_1 = np.log(p_y_1)\n",
        "for i, feature_val in enumerate(test_point):\n",
        "    log_prob_1 += np.log(p_feature_given_class[i, 1, feature_val])\n",
        "\n",
        "print(f\"Log P(X|Y=0) * P(Y=0): {log_prob_0}\")\n",
        "print(f\"Log P(X|Y=1) * P(Y=1): {log_prob_1}\")\n",
        "\n",
        "predicted_class = 1 if log_prob_1 > log_prob_0 else 0\n",
        "print(f\"Predicted label for [1, 0, 1, 0]: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J2SCm1yHxd4"
      },
      "source": [
        "## Question 6\n",
        "\n",
        "What will be the predicted label for the point $[1, 0, 1, 1]$? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tK04m9YU7cXy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log P(X|Y=0) * P(Y=0): -2.7856399198146797\n",
            "Log P(X|Y=1) * P(Y=1): -6.026105682553156\n",
            "Predicted label for [1, 0, 1, 1]: 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming these are defined: p_y_0, p_y_1, p_feature_given_class\n",
        "\n",
        "# Test point [1, 0, 1, 1]\n",
        "test_point = [1, 0, 1, 1]\n",
        "\n",
        "# Calculate P(X|Y=0) * P(Y=0)\n",
        "log_prob_0 = np.log(p_y_0)\n",
        "for i, feature_val in enumerate(test_point):\n",
        "    log_prob_0 += np.log(p_feature_given_class[i, 0, feature_val])\n",
        "\n",
        "# Calculate P(X|Y=1) * P(Y=1) \n",
        "log_prob_1 = np.log(p_y_1)\n",
        "for i, feature_val in enumerate(test_point):\n",
        "    log_prob_1 += np.log(p_feature_given_class[i, 1, feature_val])\n",
        "\n",
        "print(f\"Log P(X|Y=0) * P(Y=0): {log_prob_0}\")\n",
        "print(f\"Log P(X|Y=1) * P(Y=1): {log_prob_1}\")\n",
        "\n",
        "predicted_class = 1 if log_prob_1 > log_prob_0 else 0\n",
        "print(f\"Predicted label for [1, 0, 1, 1]: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45p6DAPA7dCl"
      },
      "source": [
        "# Gaussian naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbamhBbvjuzj"
      },
      "source": [
        "Run the below cell to get the following variables:\n",
        "\n",
        "`X_train` = Training dataset of the shape $(n, d)$. All the examples are coming from multivariate gaussian distribution.\n",
        "\n",
        "`y_train` = label vector for corresponding training examples. labels are $0$ and $1$.\n",
        "\n",
        "`X_test` = Test dataset of the shape $(m, d)$, where $m$ is the number of examples in the test dataset. All the examples are coming from multivariate gaussian distribution.\n",
        "\n",
        "`y_test` = label vector for corresponding test examples. labels are $0$ and $1$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qtqz8DPG7gok"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification, make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# generate artificial data points\n",
        "X, y = make_blobs(n_samples = 100,\n",
        "                  n_features=2, \n",
        "                  centers=[[5,5],[10,10]],\n",
        "                  cluster_std=1.5,\n",
        "                  random_state=2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRc3AVIZkphz"
      },
      "source": [
        "## Question 7\n",
        "\n",
        "How many examples are there in the trianing dataset?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9nqy1H-nkybF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of examples in training dataset: 80\n"
          ]
        }
      ],
      "source": [
        "num_train_examples = X_train.shape[0]\n",
        "print(f\"Number of examples in training dataset: {num_train_examples}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhQF7arNk6xf"
      },
      "source": [
        "## Question 8\n",
        "How many features are there in the dataset?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uoO-_Wv9lruv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features in the dataset: 2\n"
          ]
        }
      ],
      "source": [
        "num_features = X_train.shape[1]\n",
        "print(f\"Number of features in the dataset: {num_features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf2hc7NDlxm8"
      },
      "source": [
        "## Question 9\n",
        "\n",
        "If we train the Gaussian naive Bayes model on the trianing dataset, What will be the value of $\\hat{p}$, the estimate for $P(Y=1)$? Write your answer correct to two decimal places.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LpJE6KJ5mpBp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(Y=1) estimate: 0.4875\n",
            "Answer: 0.49\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming y_train is defined earlier in the code\n",
        "# For example, y_train = np.array([0, 1, 1, 0, 1]) for a binary classification problem\n",
        "\n",
        "# Calculate P(Y=1) for the Gaussian Naive Bayes training dataset\n",
        "p_y_1 = np.mean(y_train == 1)\n",
        "print(f\"P(Y=1) estimate: {p_y_1}\")\n",
        "print(f\"Answer: {p_y_1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wQUcpH7mrZr"
      },
      "source": [
        "## Question 10\n",
        "\n",
        "If $\\hat{\\mu}_0 = [\\mu_1, \\mu_2, ..., \\mu_d]$ be the estimate for $\\mu_0$, the mean of $0$ labeled examples, what will be the value of $\\mu_1+\\mu_2+...+\\mu_d$? Write your answer correct to two decimal places.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mtZ_BtxImJ0J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean for class 0: [4.55853975 5.01739665]\n",
            "Sum of mean components (μ₁ + μ₂ + ... + μₐ): 9.575936394688135\n",
            "Answer: 9.58\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming X_train and y_train are already defined\n",
        "# X_train = ...\n",
        "# y_train = ...\n",
        "\n",
        "# Calculate mean for class 0 examples\n",
        "class_0_indices = (y_train == 0)\n",
        "mu_0 = np.mean(X_train[class_0_indices], axis=0)\n",
        "sum_mu_0 = np.sum(mu_0)\n",
        "\n",
        "print(f\"Mean for class 0: {mu_0}\")\n",
        "print(f\"Sum of mean components (μ₁ + μ₂ + ... + μₐ): {sum_mu_0}\")\n",
        "print(f\"Answer: {sum_mu_0:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mnoFEJQnq9E"
      },
      "source": [
        "We will be using the different covariances for different labeled examples. The estimate for $\\Sigma_k$ will be \n",
        "\n",
        "$$\\hat{\\Sigma}_k = \\sigma_iI$$ where $\\sigma_i$ is the variance of $i^{th}$ feature values of examples labeled $k$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-aioEqdpng7"
      },
      "source": [
        "## Question 11\n",
        "What will be value of $\\text{trace}({\\hat{\\Sigma}}_0)$?  Write your answer correct to two decimal places.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ExzW4sEOqpEF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variances for class 0: [2.13298417 2.30222002]\n",
            "Trace of Σ̂₀: 4.435204194501572\n",
            "Answer: 4.44\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming X_train and y_train are already defined\n",
        "# X_train: training data features\n",
        "# y_train: training data labels\n",
        "\n",
        "# Calculate diagonal covariance matrix for class 0\n",
        "class_0_indices = (y_train == 0)\n",
        "X_class_0 = X_train[class_0_indices]\n",
        "\n",
        "# Calculate variance for each feature separately (diagonal covariance)\n",
        "sigma_0 = np.var(X_class_0, axis=0, ddof=0)  # Using ddof=0 for population variance\n",
        "trace_sigma_0 = np.sum(sigma_0)\n",
        "\n",
        "print(f\"Variances for class 0: {sigma_0}\")\n",
        "print(f\"Trace of Σ̂₀: {trace_sigma_0}\")\n",
        "print(f\"Answer: {trace_sigma_0:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKbeWd7fq1Ny"
      },
      "source": [
        "## Question 12\n",
        "\n",
        "Once we have estimated all the parameters for Gaussian naive Bayes assuming the different covariance matrices, we predict the labels for the training examples. What will be the training accuracy?\n",
        "\n",
        "Accuracy is defined as the proportion of correctly classified examples.  Write your answer correct to two decimal places.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YIg9Z1K0GwUo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.9875\n",
            "Answer: 0.99\n"
          ]
        }
      ],
      "source": [
        "# Enter your solution here\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "# Calculate parameters for each class\n",
        "class_0_indices = (y_train == 0)\n",
        "class_1_indices = (y_train == 1)\n",
        "\n",
        "# Prior probabilities\n",
        "p_y_0 = np.mean(y_train == 0)\n",
        "p_y_1 = np.mean(y_train == 1)\n",
        "\n",
        "# Means\n",
        "mu_0 = np.mean(X_train[class_0_indices], axis=0)\n",
        "mu_1 = np.mean(X_train[class_1_indices], axis=0)\n",
        "\n",
        "# Diagonal covariance matrices (independent features)\n",
        "sigma_0 = np.var(X_train[class_0_indices], axis=0, ddof=0)\n",
        "sigma_1 = np.var(X_train[class_1_indices], axis=0, ddof=0)\n",
        "\n",
        "# Create diagonal covariance matrices\n",
        "cov_0 = np.diag(sigma_0)\n",
        "cov_1 = np.diag(sigma_1)\n",
        "\n",
        "# Make predictions for training data\n",
        "predictions = []\n",
        "for x in X_train:\n",
        "    # Calculate log probabilities to avoid numerical issues\n",
        "    log_prob_0 = np.log(p_y_0) + multivariate_normal.logpdf(x, mu_0, cov_0)\n",
        "    log_prob_1 = np.log(p_y_1) + multivariate_normal.logpdf(x, mu_1, cov_1)\n",
        "    \n",
        "    pred = 1 if log_prob_1 > log_prob_0 else 0\n",
        "    predictions.append(pred)\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "training_accuracy = np.mean(predictions == y_train)\n",
        "\n",
        "print(f\"Training accuracy: {training_accuracy}\")\n",
        "print(f\"Answer: {training_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg661kj3uaxx"
      },
      "source": [
        "## Question 13\n",
        "\n",
        "What will be the test accuracy?\n",
        "\n",
        "Accuracy is defined as the proportion of correctly classified examples.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ST0Ri7TEujUw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 1.0\n",
            "Answer: 1.00\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "# Assuming the following variables are already defined from the training phase:\n",
        "# mu_0, mu_1, cov_0, cov_1, p_y_0, p_y_1\n",
        "\n",
        "# Enter your solution here\n",
        "# Make predictions for test data using the same parameters\n",
        "test_predictions = []\n",
        "for x in X_test:\n",
        "    # Calculate log probabilities to avoid numerical issues\n",
        "    log_prob_0 = np.log(p_y_0) + multivariate_normal.logpdf(x, mu_0, cov_0)\n",
        "    log_prob_1 = np.log(p_y_1) + multivariate_normal.logpdf(x, mu_1, cov_1)\n",
        "    \n",
        "    pred = 1 if log_prob_1 > log_prob_0 else 0\n",
        "    test_predictions.append(pred)\n",
        "\n",
        "test_predictions = np.array(test_predictions)\n",
        "test_accuracy = np.mean(test_predictions == y_test)\n",
        "\n",
        "print(f\"Test accuracy: {test_accuracy}\")\n",
        "print(f\"Answer: {test_accuracy:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
